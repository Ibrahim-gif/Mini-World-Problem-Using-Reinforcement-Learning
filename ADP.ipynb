{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> ADP </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "G2JaSaEAT06A"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Grid_Env: \n",
    "\tdef __init__(self,width,height,start):\n",
    "\t\tself.width = width\n",
    "\t\tself.height = height\n",
    "\t\tself.i = start[0]\n",
    "\t\tself.j = start[1]\n",
    "\n",
    "\tdef set(self,rewards, actions):\n",
    "\t\tself.rewards = rewards\n",
    "\t\tself.actions = actions\n",
    "\n",
    "\tdef set_state(self,s):\n",
    "\t\tself.i = s[0]\n",
    "\t\tself.j = s[1]\n",
    "\n",
    "\tdef current_state(self):\n",
    "\t\treturn (self.i,self.j)\n",
    "\n",
    "\tdef is_terminal(self,s):\n",
    "\t\treturn s not in self.actions\n",
    "\n",
    "\tdef move(self,action):\n",
    "\t\t'''\n",
    "\t\tchecks if a action is possible, then moves in that direction\n",
    "\t\t'''\n",
    "\t\tif action in self.actions[self.i,self.j]:\n",
    "\t\t\tif action == 'U':\n",
    "\t\t\t\tself.i -= 1\n",
    "\t\t\telif action == 'D':\n",
    "\t\t\t\tself.i += 1\n",
    "\t\t\telif action == 'R':\n",
    "\t\t\t\tself.j += 1\n",
    "\t\t\telif action == 'L':\n",
    "\t\t\t\tself.j -= 1\n",
    "\t\t#return reward if any\n",
    "\t\treturn self.rewards.get((self.i,self.j),0)\n",
    "\n",
    "\tdef all_states(self):\n",
    "\t\treturn set(list(self.actions.keys()) + list(self.rewards.keys()))\n",
    "\n",
    "# defining all possible actions that each state can perform\n",
    "def grid():\n",
    "    grd = Grid_Env(4, 6,(2,1))\n",
    "    rewards = {(1, 5): 1, (3, 5): -1, (3,4): -1}\n",
    "    actions = {\n",
    "    (0, 0): ('D','R'),\n",
    "    (0, 1): ('L','D', 'R'),\n",
    "    (0, 2): ('L','D', 'R'),\n",
    "    (0, 3): ('L','D', 'R'),\n",
    "    (0, 4): ('L','D', 'R'),\n",
    "    (0,5): ('L','D'),\n",
    "    (1, 0): ('U', 'D','R'),\n",
    "    (1, 1): ('U', 'D', 'R','L'),\n",
    "    (1, 2): ('U', 'D', 'R','L'),\n",
    "    (1, 3): ('U', 'D', 'R','L'),\n",
    "    (1, 4): ('U', 'D', 'R','L'),\n",
    "    (1, 5): ('U', 'D','L'),\n",
    "    (2, 0): ('U', 'R','D'),\n",
    "    (2, 1): ('U', 'D', 'R','L'),\n",
    "    (2, 2): ('U', 'D', 'R','L'),\n",
    "    (2, 3): ('U', 'D', 'R','L'),\n",
    "    (2, 4): ('U', 'D', 'R','L'),\n",
    "    (2, 5): ('U', 'D','L'),\n",
    "    (3, 0): ('U', 'R'),\n",
    "    (3, 1): ('L', 'R', 'U'),\n",
    "    (3, 2): ('L', 'R', 'U'),\n",
    "    (3, 3): ('L', 'R', 'U'),\n",
    "    (3, 4): ('L', 'R', 'U'),\n",
    "    (3, 5): ('L', 'U')\n",
    "    }\n",
    "    grd.set(rewards, actions)\n",
    "    return grd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "B7FEfHCvT8Xp"
   },
   "outputs": [],
   "source": [
    "GAMMA = 0.9\n",
    "ACTIONS = ('U','D','L','R')\n",
    "\n",
    "SMALL_ENOUGH = 1e-4\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    #we use the negative grid so we can make the agent as efficient as possible\n",
    "    grid = grid()\n",
    "\n",
    "\n",
    "    #state -> action\n",
    "    #well randomly choose an action and update as we learn\n",
    "    policy = {}\n",
    "    for s in grid.actions.keys():\n",
    "        policy[s] = np.random.choice(ACTIONS)\n",
    "\n",
    "    #initialize V(s)\n",
    "    V = {}\n",
    "    states = grid.all_states()\n",
    "    for s in states:\n",
    "        if s in grid.actions:\n",
    "            V[s] = np.random.random()\n",
    "        else:\n",
    "            #terminal state\n",
    "            V[s] = 0\n",
    "\n",
    "    #repeat until convergence\n",
    "    #V[s] = max[a]{sum[s',r] {p(s',r|s,a)[r + GAMMA * V[s']] } }\n",
    "    while True:\n",
    "        biggest_change = 0\n",
    "        for s in states:\n",
    "            old_v = V[s]\n",
    "\n",
    "            #V[s] only has value if not a terminal state\n",
    "            if s in policy:\n",
    "                new_v = float('-inf')\n",
    "\n",
    "                for a in ACTIONS:\n",
    "                    grid.set_state(s)\n",
    "                    r = grid.move(a)\n",
    "                    v = r + GAMMA * V[grid.current_state()]\n",
    "                    if v > new_v:\n",
    "                        new_v = v\n",
    "                V[s] = new_v\n",
    "                biggest_change = max(biggest_change, np.abs(old_v - V[s]))\n",
    "\n",
    "        if biggest_change < SMALL_ENOUGH:\n",
    "            break\n",
    "    #find a policy that leads to optimal value function\n",
    "    for s in policy.keys():\n",
    "        best_a = None\n",
    "        best_value = float('-inf')\n",
    "        for a in ACTIONS:\n",
    "            grid.set_state(s)\n",
    "            r = grid.move(a)\n",
    "            v = r + GAMMA * V[grid.current_state()]\n",
    "            if v > best_value:\n",
    "                 best_value = v\n",
    "                 best_a = a\n",
    "        policy[s] = best_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p9lyx5qPUH6e",
    "outputId": "52cbb60a-07b1-4375-a9be-ada9907249e1"
   },
   "outputs": [],
   "source": [
    "l = list(policy.values())\n",
    "l[11] = 1\n",
    "l[22] = -1\n",
    "l[23] = -1\n",
    "\n",
    "for i in range(24):\n",
    "    if(l[i] == 'R'):\n",
    "        l[i] = '→'\n",
    "    elif(l[i] == 'L'):\n",
    "        l[i] = '←'\n",
    "    elif(l[i] == 'U'):\n",
    "        l[i] = '↑'\n",
    "    elif(l[i] == 'D'):\n",
    "        l[i] = '↓'\n",
    "\n",
    "x = np.array(l)\n",
    "x = x.reshape(4,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w4g6oHwBfSSN",
    "outputId": "7f8a0e91-a3be-4669-d9a5-4d08921e780b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════╤═════╤═════╤═════╤═════╤═════╕\n",
      "│ P   │ O   │ L   │ I   │ C   │ Y   │\n",
      "╞═════╪═════╪═════╪═════╪═════╪═════╡\n",
      "│ ↓   │ ↓   │ ↓   │ ↓   │ ↓   │ ↓   │\n",
      "├─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│ →   │ →   │ →   │ →   │ →   │ 1   │\n",
      "├─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│ ↑   │ ↑   │ ↑   │ ↑   │ ↑   │ ↑   │\n",
      "├─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│ ↑   │ ↑   │ ↑   │ ↑   │ -1  │ -1  │\n",
      "╘═════╧═════╧═════╧═════╧═════╧═════╛\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "print(tabulate(x, headers='POLICY', tablefmt='fancy_grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "g2Ujxk8Xfb72"
   },
   "outputs": [],
   "source": [
    "#Get shortest path\n",
    "def get_shortest_path(i,j):\n",
    "    start_point = (i,j)\n",
    "    path = [start_point]\n",
    "    while True:\n",
    "        if x[i][j] == '1':\n",
    "            break\n",
    "        if x[i][j] == \"↓\":\n",
    "            i = i+1\n",
    "            path.append((i,j))\n",
    "        elif x[i][j] == \"↑\":\n",
    "            i = i-1\n",
    "            path.append((i,j))\n",
    "        elif x[i][j] == \"→\":\n",
    "            j = j+1\n",
    "            path.append((i,j))\n",
    "        else:\n",
    "            j = j-1\n",
    "            path.append((i,j))\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5)]\n"
     ]
    }
   ],
   "source": [
    "print(get_shortest_path(0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 1), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5)]\n"
     ]
    }
   ],
   "source": [
    "print(get_shortest_path(2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
